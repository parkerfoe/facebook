---
title: 'Part A: Data Cleaning'
---
```{r message=FALSE, warning=FALSE, include=FALSE}
library(tidyverse, quietly = T)
library(reshape2, quietly = T)
library(DBI, quietly = T)

#merging all csv files
library(data.table, quietly = T)
library(bit64, quietly = T)
library(readr, quietly = T)

```
Functions
```{r}
#Function to merge and clean all csv files (except comments)
clean <- function(file_list) {
  file_list %>%
    # https://stackoverflow.com/a/44463022
    map_df(function(x) read.csv(x, stringsAsFactors = F) %>%
             mutate(facebook = basename(x))) %>%
    mutate(facebook = tools::file_path_sans_ext(facebook)) %>%
    mutate(facebook = str_remove_all(facebook, "_.*"))
}

# Create percentage frequency tables
create_cat_tab <- function(columns) {
    tbl <- table(columns)
    res <- cbind(tbl, round(prop.table(tbl) * 100, 2))
    colnames(res) <- c("Freq", "Percentage")
    res
}
```

```{r}
# Get list of each facebook data folder
fold <- list.files(getwd(), pattern = "facebook-114-.", full.names = T)

# Get list of file names inside each data folder and store
com <- list.files(fold[1], full.names = T, pattern = "*.csv")
sent <- list.files(fold[2], full.names = T, pattern = "*.csv")
posts <- list.files(fold[3], full.names = T, pattern = "*.csv")
react <- list.files(fold[4], full.names = T, pattern = "*.csv")
```

```{r message=FALSE}
# Use the clean function and remove unnecessary columns
comments <- clean(com)
comments <- subset(comments, select = -c(message, is_reply,
                                        from_id, from_name))
```

```{r message=FALSE}

# Use the clean function and remove unnecessary columns
sentiment <- clean(sent)

# Remove duplicate columns before merging with comments
sentiment <- subset(sentiment, select = -c(facebook))

# Remove rows that have no input in any sentiment column
sentiment <- sentiment %>%
  drop_na(neg_sentiment, neu_sentiment, pos_sentiment)

# Create a new column with the strongest sentiment in that comment
nm1 <- names(sentiment)[2:4]
sentiment <- sentiment %>%
  mutate(feel = max.col(sentiment[, -1], ties.method = "first"))

sentiment$feel[sentiment$feel == 2] <- "negative"
sentiment$feel[sentiment$feel == 3] <- "neutral"
sentiment$feel[sentiment$feel == 1] <- "postive"

```

```{r message=FALSE}
post <- clean(posts)
post <- subset(post, select = -c(message, story, link))
```

```{r message=FALSE}
reaction <- clean(react)
reaction <- subset(reaction, select = -c(likes_count, facebook))
```

```{r}
# Merge comments + sentiment
com_sent <- merge(comments, sentiment, by = "id", all = T)
com_sent <- com_sent[!(com_sent$id == ""), ]

# Merge post + reaction
post_react <- merge(post, reaction, by = "id", all = T)

# Convert dates to date class
com_sent$created_time <- as.Date(com_sent$created_time, "%Y-%m-%dT")
post_react$created_time <- as.Date(post_react$created_time)

# Remove entries with NA filename
post_react <- post_react %>% drop_na(c(facebook, from_id))
com_sent <- com_sent %>% drop_na(facebook, feel)

# Write all data into csv
write.csv(post_react, "post_react.csv")
write.csv(com_sent, "com_sent.csv")
```
Summary statistics for post_react
```{r}
# categorical variables: type, from_name
summary(post_react)
nrow(post_react)
post_tab <- as.data.frame(create_cat_tab(post_react$facebook))
post_tab <- post_tab[order(-post_tab$Percentage), ]
head(post_tab)

#categorical variables: facebook
summary(com_sent)
nrow(com_sent)
com_tab <- as.data.frame(create_cat_tab(com_sent$facebook))
com_tab <- com_tab[order(-com_tab$Percentage), ]
head(com_tab)

#categorical variables: gender, type, party, state
summary(congress)
nrow(congress)
lapply(congress[c("gender", "type", "party")], create_cat_tab)
```

```{r}
# Run lintr
lintr::lint("A-data-cleaning.Rmd")
```

